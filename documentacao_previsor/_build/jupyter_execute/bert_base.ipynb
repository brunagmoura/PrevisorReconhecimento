{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca10edf27bd7de9",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5ae8aeccb13e",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:36:31.542401Z",
     "start_time": "2024-10-23T14:36:28.049736Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "#Bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import nltk\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Estilizar conteúdo\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def estilo_tabelas(df, max_altura='300px', casas_decimais=2):\n",
    "    return (\n",
    "        df.style.set_table_styles(\n",
    "            [\n",
    "                {'selector': 'thead th', 'props': [('font-size', '12px'), ('text-align', 'center'), ('border-bottom', '2px solid #007BFF')]},\n",
    "                {'selector': 'td', 'props': [('font-size', '10px'), ('text-align', 'center'), ('max-height', '40px'), ('white-space', 'nowrap'), ('text-overflow', 'ellipsis'), ('overflow', 'hidden'), ('max-width', '100px')]},\n",
    "                {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#ffffff')]},\n",
    "                {'selector': 'table', 'props': [('width', '90%'), ('margin-left', 'auto'), ('margin-right', 'auto'), ('border-collapse', 'collapse')]},\n",
    "                {'selector': 'td, th', 'props': [('border', '1px solid #666')]},\n",
    "            ]\n",
    "        ).set_properties(\n",
    "            **{'border-color': 'darkgray', 'border-style': 'solid', 'border-width': '1px'}\n",
    "        ).set_table_attributes(\n",
    "            f'style=\"height:auto; overflow:auto; max-height:{max_altura}; display:block;\"'  \n",
    "        ).format(\n",
    "            precision=casas_decimais  \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31693af69c3eef21",
   "metadata": {},
   "source": [
    "### Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de02b1fa5efa98a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:01:27.532238Z",
     "start_time": "2024-10-23T14:01:24.389650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26258 entries, 0 to 26257\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Status          26258 non-null  object\n",
      " 1   DM_Descricao    26258 non-null  object\n",
      " 2   DA_Descricao    26258 non-null  object\n",
      " 3   PEPL_Descricao  26258 non-null  object\n",
      " 4   PEPR_Descricao  26258 non-null  object\n",
      " 5   DH_Descricao    26258 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "object_columns = ['Protocolo_S2iD', 'Nome_Municipio', 'Sigla_UF', 'regiao',\n",
    "                  'Setores Censitários', 'Status', 'DH_Descricao', 'DM_Descricao',\n",
    "                  'DA_Descricao', 'DA_Polui/cont da água', 'DA_Polui/cont do ar',\n",
    "                  'DA_Polui/cont do solo', 'DA_Dimi/exauri hídrico',\n",
    "                  \"DA_Incêndi parques/APA's/APP's\", 'PEPL_Descricao', 'PEPR_Descricao',\n",
    "                  'Categoria', 'Grupo', 'Subgrupo', 'Tipo', 'Subtipo']\n",
    "\n",
    "dtype = {col: 'object' for col in object_columns}\n",
    "\n",
    "df_eventos = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/brunagmoura/PrevisorReconhecimento/refs/heads/main/df_eventos_desastres_rec_nrec.csv\",\n",
    "    sep=';',\n",
    "    decimal=',',\n",
    "    dtype=dtype)\n",
    "\n",
    "colunas_descr = [ 'Status', 'DM_Descricao',\n",
    "    'DA_Descricao',\n",
    "    'PEPL_Descricao',\n",
    "    'PEPR_Descricao',\n",
    "    'DH_Descricao' ]\n",
    "\n",
    "df_eventos_descr = df_eventos.copy()\n",
    "df_eventos_descr = df_eventos_descr[colunas_descr]\n",
    "df_eventos_descr = df_eventos_descr.fillna('')\n",
    "df_eventos_descr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa6f1dc86b410c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:02:32.306906Z",
     "start_time": "2024-10-23T14:02:32.244613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de reconhecidos:\n",
      "23871\n",
      "\n",
      "Número de não reconhecidos:\n",
      "2387\n"
     ]
    }
   ],
   "source": [
    "# Filtra o DataFrame para separar os eventos \"Reconhecidos\" e \"Não reconhecidos\"\n",
    "\n",
    "df_reconhecido = df_eventos_descr[df_eventos_descr['Status'] == 'Reconhecido']\n",
    "lista_descr_reconhecido = df_reconhecido[colunas_descr].values.tolist()\n",
    "\n",
    "df_nao_reconhecido = df_eventos_descr[df_eventos_descr['Status'] == 'Não reconhecido']\n",
    "lista_descr_nao_rec = df_nao_reconhecido[colunas_descr].values.tolist()\n",
    "\n",
    "lista_dm = df_eventos_descr['DM_Descricao'].values.tolist()\n",
    "lista_da = df_eventos_descr['DA_Descricao'].values.tolist()\n",
    "lista_pepl = df_eventos_descr['PEPL_Descricao'].values.tolist()\n",
    "lista_pepr = df_eventos_descr['PEPR_Descricao'].values.tolist()\n",
    "lista_dh = df_eventos_descr['DH_Descricao'].values.tolist()\n",
    "\n",
    "lista_dm_r = df_reconhecido['DM_Descricao'].values.tolist()\n",
    "lista_da_r = df_reconhecido['DA_Descricao'].values.tolist()\n",
    "lista_pepl_r = df_reconhecido['PEPL_Descricao'].values.tolist()\n",
    "lista_pepr_r = df_reconhecido['PEPR_Descricao'].values.tolist()\n",
    "lista_dh_r = df_reconhecido['DH_Descricao'].values.tolist()\n",
    "\n",
    "lista_dm_n = df_nao_reconhecido['DM_Descricao'].values.tolist()\n",
    "lista_da_n = df_nao_reconhecido['DA_Descricao'].values.tolist()\n",
    "lista_pepl_n = df_nao_reconhecido['PEPL_Descricao'].values.tolist()\n",
    "lista_pepr_n = df_nao_reconhecido['PEPR_Descricao'].values.tolist()\n",
    "lista_dh_n = df_nao_reconhecido['DH_Descricao'].values.tolist()\n",
    "\n",
    "## Imprime o resultado\n",
    "print('Número de reconhecidos:')\n",
    "print(len(lista_descr_reconhecido))\n",
    "print('\\nNúmero de não reconhecidos:')\n",
    "print(len(lista_descr_nao_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daa0dedd97e315b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:05:59.471721Z",
     "start_time": "2024-10-23T14:05:59.432596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '']\n",
      "['', 'NIHIL', '', 'Residencias particulares que necessitam de reparos, descontaminação e pintura. Móveis e utensílios danificados ou perdidos.', 'houve deslizamento, desbarrancamento, deslocamento da Rede Pluvial, oferendo risco às casas localizadas nas proximidades de 1,5 m (um metro e cinquenta centímetros) de distância, com cota de piso da residência a 3,5 m (três metros e cinquenta centímetros) de diferença de nível da referida avenida. Também há risco de queda de veículos sobre o telhado de cobertura das residências localizadas no lado direito ao longo da avenida; sendo necessário a construção urgente de um muro de arrimo e substituição de pavimento.', 'Destruição do de galeria de agua pluviais em tubo armico e ferro galvanizado corrugado de 2 m de diametro, e 02 adutores de água em PVC (DeFoFo) de 4 pol.', '- Nas Ruas Joaquim Ribeiro de Carvalho, Deputado Manoel Costa e Francisco Rodrigues Coura houve deslizamentos de encostas e necessita de obras ((muro de arrimo) para evitar novos desasteres.\\n\\nOBS.: Valores informados conforme planilha técnica', 'Por passar por um período de veranico no final do ano 02 casa foram queimadas pelo forte calor, além da transição de prefeito a cidade ficou acarretadas com vários problemas, com muito lixo pelas ruas, onde com o inicio das chuvas trouxe bastante prejuizo, várias casas foram alagadas no centro da cidade trazendo prejuizo com rachaduras e derrubamentos de algumas paredes. Na zona rural várias casas foram atingidas pela grande quantidade de água.', 'Em consequência dos danos/destruição, a população desabrigada foi amparado por aluguéis sociais e familiares.', '6 casas destruídas, 29 danificadas devido aos deslizamentos ocorridos muito próximos às edificações causando uma grande instabilidade, com grade risco de desabamento. 334 metros de rede coletora de esgotos danificadas, 230 metros de rede de abastecimento de água danificadas, 130 metros de rede de fornecimento de energia danificadas, 350 metros de rede de drenagem pluvial danificadas, além de 900 metros de estrada municipal com queda de barreiras.']\n"
     ]
    }
   ],
   "source": [
    "#Transforma as descrições em lista\n",
    "lista_tudo = sum([lista_dm, lista_da, lista_pepl, lista_pepr, lista_dh], [])\n",
    "lista_rec_ = sum([lista_dm_r, lista_da_r, lista_pepl_r, lista_pepr_r, lista_dh_r], [])\n",
    "lista_nao_ = sum([lista_dm_n, lista_da_n, lista_pepl_n, lista_pepr_n, lista_dh_n], [])\n",
    "\n",
    "padrao = r\"^$\"\n",
    "\n",
    "lista_rec = [string for string in lista_rec_ if not re.search(padrao, string)]\n",
    "print(lista_rec_[0:10])\n",
    "lista_nao = [string for string in lista_nao_ if not re.search(padrao, string)]\n",
    "print(lista_nao_[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507be02c2cac928",
   "metadata": {},
   "source": [
    "### Modelo BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ebe736b9136fe",
   "metadata": {},
   "source": [
    "#### Dados para rodar o modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5504f355cb563",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-23T14:36:40.866806Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Carregar o pipeline de feature-extraction com BERT\n",
    "feature_extractor = pipeline(\"feature-extraction\", model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\")\n",
    "\n",
    "# Usando lista_tudo (descrições combinadas)\n",
    "# Gera embeddings para cada descrição em lista_tudo\n",
    "embeddings = feature_extractor(lista_tudo, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Converta os embeddings para numpy para serem usados em KMeans ou outro agrupamento\n",
    "embeddings_np = np.array(embeddings)\n",
    "\n",
    "# Verifique o tamanho dos embeddings\n",
    "print(embeddings_np.shape)\n",
    "\n",
    "# Definir o número de tópicos que queremos, exemplo: 5\n",
    "n_clusters = 5\n",
    "\n",
    "# Executar o K-Means nos embeddings\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embeddings_np)\n",
    "\n",
    "# Ver os rótulos (tópicos) atribuídos a cada descrição\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Ver os resultados de tópicos atribuídos às descrições\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Descrição: {lista_tudo[i]} | Tópico: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}